{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "193610\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load ratings Change directory where appropriate\n",
    "directory = 'ml-latest-small/'\n",
    "ratings = pd.read_csv(directory+'ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "movies = pd.read_csv(directory+'movies.csv', usecols=['movieId', 'title', 'genres'])\n",
    "max_userid = ratings['userId'].drop_duplicates().max()+1\n",
    "max_movieid = ratings['movieId'].drop_duplicates().max() +1\n",
    "ratings.head()\n",
    "print(max_userid)\n",
    "print(max_movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Embedding, Reshape, Concatenate,dot,Input,Dense\n",
    "from keras.models import Model,clone_model\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "factors = 100 \n",
    "\n",
    "user_ids = ratings['userId'].values\n",
    "movie_ids = ratings['movieId'].values\n",
    "ratings_list = ratings['rating'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(max_userid = max_userid,max_movieid = max_movieid,factors=factors):\n",
    "# user_layers is the embedding layer that creates an User by latent factors matrix.\n",
    "\n",
    "    user_input = Input(shape=(1,), name = 'user_layers')\n",
    "    user_middle  = Embedding(max_userid, factors,input_length=1)(user_input)\n",
    "    user_layers  = Reshape(target_shape=(factors,))(user_middle)\n",
    "\n",
    "\n",
    "    # movie_layers is the embedding layer that creates a Movie by latent factors matrix.\n",
    "    movie_input = Input(shape=(1,), name = 'movie_layers')\n",
    "    movie_middle  = Embedding(max_movieid, factors,input_length=1)(movie_input)\n",
    "    movie_layers  = Reshape(target_shape=(factors,))(movie_middle)\n",
    "\n",
    "    output = dot([user_layers,movie_layers], axes=1)\n",
    "\n",
    "    model = Model(inputs=[user_input,movie_input], \n",
    "                      outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adamax')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice,sample\n",
    "rando = sample(range(0,len(user_ids)-1),1000)\n",
    "#print(rando)\n",
    "short_user=user_ids[rando]\n",
    "short_movie=movie_ids[rando]\n",
    "short_rate = ratings_list[rando]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"output.txt\",'w')\n",
    "#print(type(fp))\n",
    "fp.write('test'+'\\n')\n",
    "for i in short_rate:\n",
    "    fp.write(str(i)+'\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 13.5145 - val_loss: 13.0657\n",
      "Epoch 2/25\n",
      " - 11s - loss: 13.4360 - val_loss: 13.0663\n",
      "Epoch 3/25\n",
      " - 11s - loss: 13.3747 - val_loss: 13.0671\n",
      "Minimum RMSE at epoch 1 = 3.6146\n",
      "143/143 [==============================] - 0s 223us/step\n",
      "Loss is: 13.909259702775861\n",
      "Fold 2\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 14s - loss: 13.5421 - val_loss: 12.8768\n",
      "Epoch 2/25\n",
      " - 12s - loss: 13.4646 - val_loss: 12.8773\n",
      "Epoch 3/25\n",
      " - 13s - loss: 13.4031 - val_loss: 12.8775\n",
      "Minimum RMSE at epoch 1 = 3.5884\n",
      "143/143 [==============================] - 0s 251us/step\n",
      "Loss is: 13.866465081701746\n",
      "Fold 3\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 13.7312 - val_loss: 13.0828\n",
      "Epoch 2/25\n",
      " - 12s - loss: 13.6566 - val_loss: 13.0824\n",
      "Epoch 3/25\n",
      " - 12s - loss: 13.5956 - val_loss: 13.0824\n",
      "Epoch 4/25\n",
      " - 11s - loss: 13.5338 - val_loss: 13.0824\n",
      "Epoch 5/25\n",
      " - 12s - loss: 13.4685 - val_loss: 13.0828\n",
      "Minimum RMSE at epoch 3 = 3.6170\n",
      "143/143 [==============================] - 0s 398us/step\n",
      "Loss is: 12.726687751449905\n",
      "Fold 4\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 14s - loss: 13.6762 - val_loss: 13.5471\n",
      "Epoch 2/25\n",
      " - 11s - loss: 13.5974 - val_loss: 13.5475\n",
      "Epoch 3/25\n",
      " - 11s - loss: 13.5357 - val_loss: 13.5482\n",
      "Minimum RMSE at epoch 1 = 3.6806\n",
      "143/143 [==============================] - 0s 174us/step\n",
      "Loss is: 12.751989651393224\n",
      "Fold 5\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 14s - loss: 13.3498 - val_loss: 13.5505\n",
      "Epoch 2/25\n",
      " - 11s - loss: 13.2777 - val_loss: 13.5498\n",
      "Epoch 3/25\n",
      " - 11s - loss: 13.2175 - val_loss: 13.5489\n",
      "Epoch 4/25\n",
      " - 11s - loss: 13.1562 - val_loss: 13.5482\n",
      "Epoch 5/25\n",
      " - 11s - loss: 13.0919 - val_loss: 13.5476\n",
      "Epoch 6/25\n",
      " - 11s - loss: 13.0237 - val_loss: 13.5470\n",
      "Epoch 7/25\n",
      " - 10s - loss: 12.9516 - val_loss: 13.5465\n",
      "Epoch 8/25\n",
      " - 11s - loss: 12.8738 - val_loss: 13.5464\n",
      "Epoch 9/25\n",
      " - 11s - loss: 12.7909 - val_loss: 13.5457\n",
      "Epoch 10/25\n",
      " - 12s - loss: 12.7020 - val_loss: 13.5451\n",
      "Epoch 11/25\n",
      " - 12s - loss: 12.6060 - val_loss: 13.5450\n",
      "Epoch 12/25\n",
      " - 12s - loss: 12.5031 - val_loss: 13.5446\n",
      "Epoch 13/25\n",
      " - 13s - loss: 12.3947 - val_loss: 13.5446\n",
      "Epoch 14/25\n",
      " - 12s - loss: 12.2783 - val_loss: 13.5446\n",
      "Epoch 15/25\n",
      " - 14s - loss: 12.1552 - val_loss: 13.5446\n",
      "Minimum RMSE at epoch 13 = 3.6803\n",
      "143/143 [==============================] - 0s 91us/step\n",
      "Loss is: 14.512311962101009\n",
      "Fold 6\n",
      "Train on 771 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 15s - loss: 13.4913 - val_loss: 13.7595\n",
      "Epoch 2/25\n",
      " - 11s - loss: 13.4149 - val_loss: 13.7600\n",
      "Epoch 3/25\n",
      " - 11s - loss: 13.3543 - val_loss: 13.7604\n",
      "Minimum RMSE at epoch 1 = 3.7094\n",
      "143/143 [==============================] - 0s 174us/step\n",
      "Loss is: 13.617101089104072\n",
      "Fold 7\n",
      "Train on 772 samples, validate on 86 samples\n",
      "Epoch 1/25\n",
      " - 13s - loss: 13.5352 - val_loss: 13.8366\n",
      "Epoch 2/25\n",
      " - 11s - loss: 13.4588 - val_loss: 13.8365\n",
      "Epoch 3/25\n",
      " - 11s - loss: 13.3985 - val_loss: 13.8368\n",
      "Epoch 4/25\n",
      " - 11s - loss: 13.3373 - val_loss: 13.8371\n",
      "Minimum RMSE at epoch 2 = 3.7197\n",
      "142/142 [==============================] - 0s 70us/step\n",
      "Loss is: 13.328061667966171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import math\n",
    "\n",
    "#noramlly random, but its for reprodcbility\n",
    "kfold = KFold(n_splits=7, shuffle=True, random_state=np.random.seed(10))\n",
    "scores = []\n",
    "rmses = []\n",
    "min_epochs = []\n",
    "i = 0\n",
    "for train, test in kfold.split(ratings_list):\n",
    "    \n",
    "    i+=1 \n",
    "    print(\"Fold {}\".format(i))\n",
    "    weight_string = 'test/weights'+str(i)+'.h5'\n",
    "    model = model_maker()\n",
    "    callbacks = [EarlyStopping('val_loss', patience=2),  ModelCheckpoint(weight_string, save_best_only=True)]\n",
    "    history = model.fit([user_ids[train],movie_ids[train]],ratings_list[train], epochs=25, validation_split=.1, verbose=2, callbacks=callbacks)\n",
    "      \n",
    "    min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "    rmses.append(min_val_loss)\n",
    "    min_epochs.append(idx)\n",
    "    print( 'Minimum RMSE at epoch ' + '{:d}'.format(idx+1) + ' = '+ '{:.4f}'.format(math.sqrt(min_val_loss)))\n",
    "    score = model.evaluate([user_ids[test],movie_ids[test]],ratings_list[tst])\n",
    "    print('Loss is: {}'.format(score))\n",
    "    scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5415% (+/- 0.0120%)\n",
      "[1.5378864061997248, 1.5474179587334433, 1.561328424377157, 1.5430102679342337, 1.519050771275815, 1.5465742985417397, 1.5349368303138387]\n",
      "1.8340% (+/- 0.0030%)\n",
      "[1.836997025225401, 1.8329663511431422, 1.835992808685128, 1.837312900144314, 1.8281652086119626, 1.8345682820374172, 1.8320836752015814]\n"
     ]
    }
   ],
   "source": [
    "rmses = [math.sqrt(item) for item in rmses]\n",
    "print(\"{:.4f}% (+/- {:.4f}%)\".format(np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "\n",
    "print(\"{:.4f}% (+/- {:.4f}%)\".format(np.mean(rmses), np.std(rmses)))\n",
    "print(rmses)\n",
    "\n",
    "fp = open(\"output.csv\",'w')\n",
    "#print(type(fp))\n",
    "fp.write('fold,min_epoch,rmse,loss_score'+'\\n')\n",
    "for i in range(len(scores)):\n",
    "    fp.write(str(i)+','+str(min_epochs[i])+','+str(rmses[i])+','+str(scores[i])+','+'\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pre-trained model\n",
    "trained_model = clone_model(model)\n",
    "# Load weights\n",
    "trained_model.load_weights('movie_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_id, movie_id):\n",
    "    return trained_model.predict([np.array([user_id]), np.array([movie_id])])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_user = 450#choice(user_ids)\n",
    "rand_movie = choice(movie_ids)\n",
    "\n",
    "user_ratings = ratings[ratings['userId'] == rand_user][['userId', 'movieId', 'rating']]\n",
    "#print(ratings[ratings['userId'] == rand_user][['userId', 'movieId','rating']])\n",
    "user_ratings['prediction'] = user_ratings.apply(lambda x: predict_rating(rand_user, x['movieId']), axis=1)\n",
    "user_ratings.sort_values(by='rating', \n",
    "                         ascending=False).merge(movies, \n",
    "                                                on='movieId', \n",
    "                                                how='inner', \n",
    "                                                suffixes=['_u', '_m']).head(20)\n",
    "\n",
    "#print(user_ratings['prediction'].values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = ratings[ratings['movieId'].isin(user_ratings['movieId']) == False][['movieId']].drop_duplicates()\n",
    "recommendations['prediction'] = recommendations.apply(lambda x: predict_rating(rand_user, x['movieId']), axis=1)\n",
    "recommendations.sort_values(by='prediction',\n",
    "                          ascending=False).merge(movies,\n",
    "                                                 on='movieId',\n",
    "                                                 how='inner',\n",
    "                                                 suffixes=['_u', '_m']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((movie_ids.size,1))\n",
    "#print(matrix)\n",
    "for user in user_ids:\n",
    "    newcol = np.array([predict_rating(user, movie) for movie in movie_ids])\n",
    "    newcol.shape=((movie_ids.size,1))\n",
    "    matrix = np.hstack((matrix,newcol))\n",
    "matrix = matrix[:,1:]\n",
    "print(matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
